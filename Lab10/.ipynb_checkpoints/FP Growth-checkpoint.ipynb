{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "000881da-1902-483f-aec6-7fcae2323f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yubar\\anaconda3\\envs\\spark_env\\lib\\site-packages\\pyspark\\sql\\context.py:113: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkContext\n",
    "from pyspark.ml.fpm import FPGrowth\n",
    "SparkContext.getOrCreate()\n",
    "sc = SparkContext.getOrCreate(\"FP-Growth\")\n",
    "sqlCtx = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ee4b83a-5681-467a-a536-3038a40d0ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+\n",
      "|    items|freq|\n",
      "+---------+----+\n",
      "|      [A]|   7|\n",
      "|      [B]|   6|\n",
      "|   [B, A]|   4|\n",
      "|      [S]|   6|\n",
      "|   [S, B]|   4|\n",
      "|[S, B, A]|   2|\n",
      "|   [S, A]|   4|\n",
      "|      [C]|   2|\n",
      "|   [C, A]|   2|\n",
      "|      [T]|   2|\n",
      "|   [T, B]|   2|\n",
      "|[T, B, A]|   2|\n",
      "|   [T, A]|   2|\n",
      "+---------+----+\n",
      "\n",
      "+----------+----------+------------------+------------------+------------------+\n",
      "|antecedent|consequent|        confidence|              lift|           support|\n",
      "+----------+----------+------------------+------------------+------------------+\n",
      "|    [T, A]|       [B]|               1.0|               1.5|0.2222222222222222|\n",
      "|    [B, A]|       [S]|               0.5|              0.75|0.2222222222222222|\n",
      "|    [B, A]|       [T]|               0.5|              2.25|0.2222222222222222|\n",
      "|       [B]|       [A]|0.6666666666666666|0.8571428571428571|0.4444444444444444|\n",
      "|       [B]|       [S]|0.6666666666666666|               1.0|0.4444444444444444|\n",
      "|       [B]|       [T]|0.3333333333333333|               1.5|0.2222222222222222|\n",
      "|       [C]|       [A]|               1.0|1.2857142857142856|0.2222222222222222|\n",
      "|       [A]|       [B]|0.5714285714285714|0.8571428571428571|0.4444444444444444|\n",
      "|       [A]|       [S]|0.5714285714285714|0.8571428571428571|0.4444444444444444|\n",
      "|       [A]|       [C]|0.2857142857142857|1.2857142857142858|0.2222222222222222|\n",
      "|       [A]|       [T]|0.2857142857142857|1.2857142857142858|0.2222222222222222|\n",
      "|       [T]|       [B]|               1.0|               1.5|0.2222222222222222|\n",
      "|       [T]|       [A]|               1.0|1.2857142857142856|0.2222222222222222|\n",
      "|    [S, B]|       [A]|               0.5|0.6428571428571428|0.2222222222222222|\n",
      "|       [S]|       [B]|0.6666666666666666|               1.0|0.4444444444444444|\n",
      "|       [S]|       [A]|0.6666666666666666|0.8571428571428571|0.4444444444444444|\n",
      "|    [S, A]|       [B]|               0.5|              0.75|0.2222222222222222|\n",
      "|    [T, B]|       [A]|               1.0|1.2857142857142856|0.2222222222222222|\n",
      "+----------+----------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = sqlCtx.createDataFrame([ # Create Dataframe from datasets\n",
    "    (0, [\"B\", \"A\", \"T\"]),       # Dataset 1\n",
    "    (1, [\"A\", \"C\"]),            # Dataset 2\n",
    "    (2, [\"A\", \"S\"]),            # Dataset 3\n",
    "    (3, [\"B\", \"A\", \"C\"]),       # Dataset 4\n",
    "    (4, [\"B\", \"S\"]),            # Dataset 5\n",
    "    (5, [\"A\", \"S\"]),            # Dataset 6\n",
    "    (6, [\"B\", \"S\"]),            # Dataset 7\n",
    "    (7, [\"B\", \"A\", \"S\", \"T\"]),  # Dataset 8\n",
    "    (8, [\"B\", \"A\", \"S\"])        # Dataset 9\n",
    "], [\"id\", \"items\"]) # Name of the columns\n",
    "\n",
    "fpGrowth = FPGrowth(itemsCol=\"items\", minSupport=0.2, minConfidence=0.2)\n",
    "# minSupport: the minimum support for an itemset to be identified as frequent. \n",
    "# For example, if an item appears 3 out of 9 transactions, it has a support of 3/9=0.6.\n",
    "\n",
    "# minConfidence: minimum confidence for generating Association Rule. \n",
    "# Confidence is an indication of how often an association rule has been found to be true. \n",
    "# For example, if in the transactions itemset X appears 4 times, X and Y co-occur only 2 times, \n",
    "# the confidence for the rule X => Y is then 2/4 = 0.5. The parameter will not affect the mining for frequent itemsets, \n",
    "# but specify the minimum confidence for generating association rules from frequent itemsets.\n",
    "\n",
    "# Fit the fpGrowth model to the data\n",
    "model = fpGrowth.fit(df)\n",
    "\n",
    "# Display frequent itemsets.\n",
    "model.freqItemsets.show()\n",
    "\n",
    "# Display generated association rules.\n",
    "model.associationRules.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d244c2b-73e4-45cf-87e5-9aeac5007777",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (spark_env)",
   "language": "python",
   "name": "spark_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
